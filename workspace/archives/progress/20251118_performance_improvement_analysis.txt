================================================================================
ADMET 모델 성능 개선을 위한 종합 분석 보고서
================================================================================
작성일: 2025-11-18

1. 클래스 불균형 분석
================================================================================

1.1 전체 현황
- 총 21개 분류 데이터셋 분석
- 심각도 분포:
  * Balanced (1:1.5 미만)    : 8 datasets (38%)
  * Slight (1:1.5~3)         : 5 datasets (24%)
  * Moderate (1:3~5)         : 4 datasets (19%)
  * High (1:5~10)            : 2 datasets (10%)
  * Severe (1:10 이상)       : 2 datasets (10%)

1.2 가장 불균형한 데이터셋 TOP 5
1. hERG_Central_inhib  : 21.50:1 (Severe) - 4.4% positive
2. ClinTox             : 13.55:1 (Severe) - 6.9% positive
3. HIA_Hou             :  8.18:1 (High)   - 89.1% positive
4. PAMPA_NCATS         :  5.32:1 (High)   - 84.2% positive
5. CYP2C9_Substrate    :  4.20:1 (Moderate) - 19.2% positive

1.3 불균형 vs 성능 상관관계
- Pearson 상관계수: -0.0121 (매우 약한 음의 상관)
- 심각도별 평균 AUROC:
  * Balanced  : 82.75% ± 7.97%
  * Slight    : 80.18% ± 6.16%
  * Moderate  : 74.75% ± 8.19%  ← 가장 낮음
  * High      : 85.26% ± 10.63%
  * Severe    : 77.48% ± 6.45%

→ 결론: Moderate 불균형(1:3~5)에서 성능이 가장 낮음
         Severe 불균형은 오히려 High보다 낮은 성능


2. 데이터셋 크기 분석
================================================================================

2.1 크기별 분포
- Tiny (<500)         : 3 datasets
- Small (500-1K)      : 6 datasets
- Medium (1K-5K)      : 4 datasets
- Large (5K-10K)      : 1 dataset
- Very Large (>10K)   : 7 datasets

2.2 크기별 평균 성능
- Tiny (<500)         : 79.68% ± 6.93%
- Small (500-1K)      : 75.15% ± 11.11%  ← 가장 낮고 편차 큼
- Medium (1K-5K)      : 79.57% ± 7.01%
- Large (5K-10K)      : 78.68% (n=1)
- Very Large (>10K)   : 85.78% ± 2.82%   ← 가장 높고 안정적

2.3 크기 vs 성능 상관관계
- Pearson 상관계수: 0.1296 (약한 양의 상관)
→ 결론: 데이터셋이 클수록 성능이 약간 향상되는 경향


3. 저성능 데이터셋 심층 분석 (AUROC < 75%)
================================================================================

3.1 저성능 데이터셋 목록 (7개)
Dataset                          AUROC   크기    불균형   문제점
--------------------------------------------------------------------------
CYP3A4_Substrate_CarbonMangels  64.08%   670   Balanced  작은 크기
Bioavailability_Ma              64.62%   640   Moderate  작은 크기 + 불균형
CYP2C9_Substrate_CarbonMangels  69.80%   669   Moderate  작은 크기 + 불균형
ClinTox                         71.03%  1478   Severe    심각한 불균형
Skin_Reaction                   71.79%   404   Slight    매우 작은 크기
hERG                            74.48%   655   Slight    작은 크기
PAMPA_NCATS                     74.63%  2034   High      심각한 불균형

3.2 공통 문제점
1) CYP Substrate 3종: 작은 데이터셋 (<700 samples)
   - 특징: 기질(substrate) 예측은 억제(inhibitor)보다 어려움
   - CYP 억제 모델: 평균 85% AUROC
   - CYP 기질 모델: 평균 65% AUROC

2) 불균형 문제: ClinTox, PAMPA_NCATS
   - 극심한 클래스 불균형 (>5:1)

3) 데이터 부족: Skin_Reaction, Bioavailability_Ma
   - 전체 샘플 < 650개


4. 성능 향상 전략 제안
================================================================================

4.1 우선순위 1: Focal Loss 적용 (추정 개선폭: +3~8%)
대상 데이터셋:
- ClinTox (13.55:1 불균형)
- PAMPA_NCATS (5.32:1 불균형)
- Bioavailability_Ma (3.31:1 불균형)
- CYP2C9_Substrate (4.20:1 불균형)

권장 하이퍼파라미터:
- focal_alpha: [0.25, 0.5, 0.75] (minority class 가중치)
- focal_gamma: [1.0, 2.0, 3.0] (hard example focus)

예상 효과:
- ClinTox: 71% → 76~79%
- PAMPA_NCATS: 75% → 78~82%


4.2 우선순위 2: 데이터 증강 (추정 개선폭: +2~5%)
대상 데이터셋:
- CYP3A4_Substrate (670 samples)
- CYP2C9_Substrate (669 samples)
- CYP2D6_Substrate (실제 성능 82%, 개선 가능)
- Skin_Reaction (404 samples)
- Bioavailability_Ma (640 samples)

방법:
1) SMILES Enumeration
   - 동일 분자의 다른 SMILES 표현 생성
   - 2~5배 증강 가능
   
2) Molecular Scaffolding
   - 유사 scaffold 분자로 pre-training
   
3) Graph Augmentation
   - Edge dropout, Node feature masking


4.3 우선순위 3: Class Weighting (추정 개선폭: +1~3%)
대상: 모든 불균형 데이터셋

방법:
- pos_weight = neg_count / pos_count in BCEWithLogitsLoss
- 구현 간단, 부작용 적음


4.4 우선순위 4: 앙상블 학습 (추정 개선폭: +2~4%)
대상: CYP Substrate 3종

방법:
1) CYP Inhibitor 모델에서 Transfer Learning
2) Multi-task Learning (Substrate + Inhibitor 동시 학습)
3) 5-fold Cross-Validation 앙상블


4.5 우선순위 5: 학습률 및 정규화 조정
대상: 성능 악화 데이터셋 (final < tuning)

문제 데이터셋:
- CYP1A2_Veith: -6.32% 악화
- CYP3A4_Veith: -3.26% 악화
- Bioavailability_Ma: -6.32% 악화

원인:
- Train+Valid 결합으로 과적합 발생
- Dropout ratio 재조정 필요

해결책:
- Dropout: 0.5 → 0.3
- Learning rate decay 적용
- Weight decay 증가: 0 → 0.0001


5. 실험 계획 (단계별 접근)
================================================================================

Phase 1: Focal Loss 실험 (1-2일)
------------------------------------
목표: 불균형 문제 해결

Step 1: Focal Loss 구현
- TopExpert.py에 FocalLoss 클래스 추가
- main.py에 --loss_type, --focal_alpha, --focal_gamma 인자 추가

Step 2: Grid Search (4개 데이터셋)
- ClinTox, PAMPA_NCATS, Bioavailability_Ma, CYP2C9_Substrate
- alpha: [0.25, 0.5, 0.75]
- gamma: [1.0, 2.0, 3.0]
- Total: 4 datasets × 9 configs = 36 runs

Step 3: 최적 설정으로 전체 불균형 데이터셋 재학습
- Moderate/High/Severe 불균형 8개 데이터셋


Phase 2: 데이터 증강 실험 (2-3일)
------------------------------------
목표: 작은 데이터셋 성능 향상

Step 1: SMILES Enumeration 구현
- RDKit MolToSmiles with doRandom=True
- 각 분자당 5개 SMILES 생성

Step 2: 작은 데이터셋 재학습
- CYP Substrate 3종
- Skin_Reaction, Bioavailability_Ma

Step 3: 성능 평가
- Original vs Augmented 비교


Phase 3: 종합 최적화 (2-3일)
------------------------------------
목표: 전체 모델 재학습

Step 1: 최적 설정 적용
- Focal Loss (불균형 데이터셋)
- Data Augmentation (작은 데이터셋)
- Class Weighting (나머지)

Step 2: 33개 전체 모델 재학습

Step 3: 성능 비교 및 문서화


6. 예상 성능 향상
================================================================================

현재 전체 평균 AUROC: 80.35%

Phase 1 완료 후 (Focal Loss):
- 저성능 4개 데이터셋: 68-72% → 75-79%
- 전체 평균: 80.35% → 81.5~82.0%

Phase 2 완료 후 (+ Data Augmentation):
- CYP Substrate: 65% → 70-72%
- 전체 평균: 81.5% → 82.5~83.0%

Phase 3 완료 후 (종합):
- 전체 평균: 82.5% → 83.5~84.0%
- 최저 성능: 64% → 70%+
- AUROC < 75% 데이터셋: 7개 → 2~3개


7. 구현 시 주의사항
================================================================================

1) Focal Loss 구현
   - reduction='none' 유지 (TopExpert의 expert별 loss 계산 위해)
   - alpha balancing 신중하게 적용

2) 데이터 증강
   - Test set은 절대 증강하지 않음
   - Train/Valid만 증강
   - 원본 데이터 보존

3) 재현성
   - Random seed 고정
   - 증강 방법 문서화

4) 평가
   - Baseline과 공정한 비교
   - Test set으로만 평가


8. 결론
================================================================================

현재 성능 저하의 주요 원인:
1. 클래스 불균형 (특히 1:3~13 범위)
2. 작은 데이터셋 크기 (<700 samples)
3. CYP Substrate와 같은 본질적으로 어려운 task

개선 가능성:
- Focal Loss: 높음 (검증된 방법, 즉시 적용 가능)
- Data Augmentation: 중간 (효과적이나 구현 필요)
- Class Weighting: 낮음~중간 (간단하나 효과 제한적)

권장 접근:
1. Focal Loss 우선 적용 (빠른 효과)
2. 성능 개선 확인 후 Data Augmentation 추가
3. 단계별 평가 후 전체 모델 재학습

================================================================================
End of Report
================================================================================
