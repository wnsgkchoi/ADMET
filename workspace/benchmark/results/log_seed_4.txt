Set CUDA_VISIBLE_DEVICES=3
Running specific seed: seed_4

==================================================
Running seed_4...
==================================================
  Optimizing XGBoost...
[I 2025-11-23 16:15:46,202] A new study created in memory with name: no-name-4d36d5c1-7c44-40e1-81d1-563f34edfac8
  0%|          | 0/10 [00:00<?, ?it/s]/home/choi0425/miniconda3/envs/ADMET/lib/python3.11/site-packages/xgboost/core.py:729: UserWarning: [16:15:48] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.
Potential solutions:
- Use a data structure that matches the device ordinal in the booster.
- Set the device for booster before call to inplace_predict.

This warning will only be shown once.

  return func(**kwargs)
                                      [I 2025-11-23 16:15:48,530] Trial 0 finished with value: 0.8235503364692491 and parameters: {'learning_rate': 0.042453103985452226, 'n_estimators': 122, 'max_depth': 8, 'min_child_weight': 15, 'subsample': 0.7393485706910952, 'colsample_bytree': 0.9122425139298822, 'gamma': 0.49792867466959656, 'reg_alpha': 7.858484841037791, 'reg_lambda': 5.6691037226503384e-05}. Best is trial 0 with value: 0.8235503364692491.
  0%|          | 0/10 [00:02<?, ?it/s]Best trial: 0. Best value: 0.82355:   0%|          | 0/10 [00:02<?, ?it/s]Best trial: 0. Best value: 0.82355:  10%|█         | 1/10 [00:02<00:20,  2.33s/it]                                                                                  [I 2025-11-23 16:15:49,513] Trial 1 finished with value: 0.8401980314037965 and parameters: {'learning_rate': 0.05849724400391036, 'n_estimators': 153, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.737801477675899, 'colsample_bytree': 0.5250402354575265, 'gamma': 2.1232435780818966, 'reg_alpha': 9.776024742219125e-06, 'reg_lambda': 0.0001349111773108099}. Best is trial 1 with value: 0.8401980314037965.
Best trial: 0. Best value: 0.82355:  10%|█         | 1/10 [00:03<00:20,  2.33s/it]Best trial: 1. Best value: 0.840198:  10%|█         | 1/10 [00:03<00:20,  2.33s/it]Best trial: 1. Best value: 0.840198:  20%|██        | 2/10 [00:03<00:12,  1.54s/it]                                                                                   [I 2025-11-23 16:15:51,005] Trial 2 finished with value: 0.8363729954133048 and parameters: {'learning_rate': 0.23738341861825124, 'n_estimators': 946, 'max_depth': 5, 'min_child_weight': 11, 'subsample': 0.9388427936224408, 'colsample_bytree': 0.851064444732887, 'gamma': 4.078321171430835, 'reg_alpha': 0.24984914800184385, 'reg_lambda': 1.904047094484416}. Best is trial 1 with value: 0.8401980314037965.
Best trial: 1. Best value: 0.840198:  20%|██        | 2/10 [00:04<00:12,  1.54s/it]Best trial: 1. Best value: 0.840198:  20%|██        | 2/10 [00:04<00:12,  1.54s/it]Best trial: 1. Best value: 0.840198:  30%|███       | 3/10 [00:04<00:10,  1.52s/it]                                                                                   [I 2025-11-23 16:15:52,611] Trial 3 finished with value: 0.8429349827580435 and parameters: {'learning_rate': 0.19196474982840822, 'n_estimators': 792, 'max_depth': 8, 'min_child_weight': 11, 'subsample': 0.8276383481920373, 'colsample_bytree': 0.522395026170133, 'gamma': 3.932617010737247, 'reg_alpha': 0.022775802789366372, 'reg_lambda': 2.406888080212691e-06}. Best is trial 3 with value: 0.8429349827580435.
Best trial: 1. Best value: 0.840198:  30%|███       | 3/10 [00:06<00:10,  1.52s/it]Best trial: 3. Best value: 0.842935:  30%|███       | 3/10 [00:06<00:10,  1.52s/it]Best trial: 3. Best value: 0.842935:  40%|████      | 4/10 [00:06<00:09,  1.55s/it]                                                                                   [I 2025-11-23 16:15:54,114] Trial 4 finished with value: 0.8388923298403027 and parameters: {'learning_rate': 0.13724416017934057, 'n_estimators': 973, 'max_depth': 3, 'min_child_weight': 11, 'subsample': 0.8671721837635362, 'colsample_bytree': 0.9416560855205178, 'gamma': 3.4911639496602516, 'reg_alpha': 0.020494805204615028, 'reg_lambda': 2.464623866560975e-07}. Best is trial 3 with value: 0.8429349827580435.
Best trial: 3. Best value: 0.842935:  40%|████      | 4/10 [00:07<00:09,  1.55s/it]Best trial: 3. Best value: 0.842935:  40%|████      | 4/10 [00:07<00:09,  1.55s/it]Best trial: 3. Best value: 0.842935:  50%|█████     | 5/10 [00:07<00:07,  1.53s/it]                                                                                   [I 2025-11-23 16:15:55,527] Trial 5 finished with value: 0.8298947068867386 and parameters: {'learning_rate': 0.03388488113093701, 'n_estimators': 312, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.8439940720598, 'colsample_bytree': 0.9816872332986647, 'gamma': 0.6784789889528381, 'reg_alpha': 0.10625615108388654, 'reg_lambda': 0.02609164779990219}. Best is trial 3 with value: 0.8429349827580435.
Best trial: 3. Best value: 0.842935:  50%|█████     | 5/10 [00:09<00:07,  1.53s/it]Best trial: 3. Best value: 0.842935:  50%|█████     | 5/10 [00:09<00:07,  1.53s/it]Best trial: 3. Best value: 0.842935:  60%|██████    | 6/10 [00:09<00:05,  1.49s/it]                                                                                   [I 2025-11-23 16:15:56,523] Trial 6 finished with value: 0.8292251163413573 and parameters: {'learning_rate': 0.09513568307169937, 'n_estimators': 324, 'max_depth': 4, 'min_child_weight': 17, 'subsample': 0.5157561672458442, 'colsample_bytree': 0.610094759893492, 'gamma': 1.7723040815319868, 'reg_alpha': 0.05068957638844263, 'reg_lambda': 2.908372753414919e-06}. Best is trial 3 with value: 0.8429349827580435.
Best trial: 3. Best value: 0.842935:  60%|██████    | 6/10 [00:10<00:05,  1.49s/it]Best trial: 3. Best value: 0.842935:  60%|██████    | 6/10 [00:10<00:05,  1.49s/it]Best trial: 3. Best value: 0.842935:  70%|███████   | 7/10 [00:10<00:03,  1.33s/it]                                                                                   [I 2025-11-23 16:15:57,821] Trial 7 finished with value: 0.8368751883223408 and parameters: {'learning_rate': 0.050816379939944256, 'n_estimators': 328, 'max_depth': 7, 'min_child_weight': 11, 'subsample': 0.5794669061564652, 'colsample_bytree': 0.7198806607621717, 'gamma': 3.8782518831986708, 'reg_alpha': 0.07432435286184484, 'reg_lambda': 0.001986689033902069}. Best is trial 3 with value: 0.8429349827580435.
Best trial: 3. Best value: 0.842935:  70%|███████   | 7/10 [00:11<00:03,  1.33s/it]Best trial: 3. Best value: 0.842935:  70%|███████   | 7/10 [00:11<00:03,  1.33s/it]Best trial: 3. Best value: 0.842935:  80%|████████  | 8/10 [00:11<00:02,  1.32s/it]                                                                                   [I 2025-11-23 16:16:00,148] Trial 8 finished with value: 0.8304931534366735 and parameters: {'learning_rate': 0.26973332875315625, 'n_estimators': 906, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.9478753565067829, 'colsample_bytree': 0.5707129233080122, 'gamma': 0.029863101254763436, 'reg_alpha': 1.3578725814850298e-08, 'reg_lambda': 2.966806013741181e-08}. Best is trial 3 with value: 0.8429349827580435.
Best trial: 3. Best value: 0.842935:  80%|████████  | 8/10 [00:13<00:02,  1.32s/it]Best trial: 3. Best value: 0.842935:  80%|████████  | 8/10 [00:13<00:02,  1.32s/it]Best trial: 3. Best value: 0.842935:  90%|█████████ | 9/10 [00:13<00:01,  1.63s/it]                                                                                   [I 2025-11-23 16:16:03,663] Trial 9 finished with value: 0.8472161773075765 and parameters: {'learning_rate': 0.023491246256031596, 'n_estimators': 835, 'max_depth': 9, 'min_child_weight': 9, 'subsample': 0.7428042920959728, 'colsample_bytree': 0.9995803992486215, 'gamma': 1.4153625782471968, 'reg_alpha': 0.00019774597957063228, 'reg_lambda': 1.0046722553936167}. Best is trial 9 with value: 0.8472161773075765.
Best trial: 3. Best value: 0.842935:  90%|█████████ | 9/10 [00:17<00:01,  1.63s/it]Best trial: 9. Best value: 0.847216:  90%|█████████ | 9/10 [00:17<00:01,  1.63s/it]Best trial: 9. Best value: 0.847216: 100%|██████████| 10/10 [00:17<00:00,  2.22s/it]Best trial: 9. Best value: 0.847216: 100%|██████████| 10/10 [00:17<00:00,  1.75s/it]
    Best Valid AUROC: 0.8472
    Test AUROC: 0.8626
  Optimizing LightGBM...
[I 2025-11-23 16:16:07,474] A new study created in memory with name: no-name-b77201a0-6dc8-4984-b85a-dfa2bb16098a
  0%|          | 0/10 [00:00<?, ?it/s]/home/choi0425/miniconda3/envs/ADMET/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names
  warnings.warn(
/home/choi0425/miniconda3/envs/ADMET/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names
  warnings.warn(
                                      [I 2025-11-23 16:24:47,181] Trial 0 finished with value: 0.8418678228263416 and parameters: {'learning_rate': 0.11084687783542738, 'n_estimators': 950, 'num_leaves': 149, 'max_depth': 3, 'min_child_samples': 88, 'subsample': 0.554219687371222, 'colsample_bytree': 0.9738024325116899, 'feature_fraction': 0.890771438379813, 'bagging_fraction': 0.8889432676924149, 'bagging_freq': 0, 'lambda_l1': 8.828227829775108e-06, 'lambda_l2': 1.8033385633011276e-07, 'min_split_gain': 0.7135207006729012, 'max_bin': 80}. Best is trial 0 with value: 0.8418678228263416.
  0%|          | 0/10 [08:39<?, ?it/s]Best trial: 0. Best value: 0.841868:   0%|          | 0/10 [08:39<?, ?it/s]Best trial: 0. Best value: 0.841868:  10%|█         | 1/10 [08:39<1:17:57, 519.71s/it]/home/choi0425/miniconda3/envs/ADMET/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names
  warnings.warn(
/home/choi0425/miniconda3/envs/ADMET/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names
  warnings.warn(
                                                                                      [I 2025-11-23 16:31:59,506] Trial 1 finished with value: 0.8225752452375373 and parameters: {'learning_rate': 0.2553590403146843, 'n_estimators': 349, 'num_leaves': 56, 'max_depth': 3, 'min_child_samples': 46, 'subsample': 0.8046378996367589, 'colsample_bytree': 0.8814144532445374, 'feature_fraction': 0.6467376665977813, 'bagging_fraction': 0.5610838394010176, 'bagging_freq': 9, 'lambda_l1': 3.273701002030804e-08, 'lambda_l2': 2.3359963473963017e-08, 'min_split_gain': 0.9685327495482353, 'max_bin': 116}. Best is trial 0 with value: 0.8418678228263416.
Best trial: 0. Best value: 0.841868:  10%|█         | 1/10 [15:52<1:17:57, 519.71s/it]Best trial: 0. Best value: 0.841868:  10%|█         | 1/10 [15:52<1:17:57, 519.71s/it]Best trial: 0. Best value: 0.841868:  20%|██        | 2/10 [15:52<1:02:26, 468.31s/it]